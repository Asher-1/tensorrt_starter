&&&& RUNNING TensorRT.trtexec [TensorRT v8501] # trtexec --onnx=sample.onnx --memPoolSize=workspace:2048 --saveEngine=sample.engine --verbose --profilingVerbosity=layer_names_only --dumpOutput --dumpProfile --dumpLayerInfo --exportOutput=log/sample/build/build_output.log --exportProfile=log/sample/build/build_profile.log --exportLayerInfo=log/sample/build/build_layer_info.log --warmUp=200 --iterations=50
[05/28/2023-14:30:02] [I] === Model Options ===
[05/28/2023-14:30:02] [I] Format: ONNX
[05/28/2023-14:30:02] [I] Model: sample.onnx
[05/28/2023-14:30:02] [I] Output:
[05/28/2023-14:30:02] [I] === Build Options ===
[05/28/2023-14:30:02] [I] Max batch: explicit batch
[05/28/2023-14:30:02] [I] Memory Pools: workspace: 2048 MiB, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default
[05/28/2023-14:30:02] [I] minTiming: 1
[05/28/2023-14:30:02] [I] avgTiming: 8
[05/28/2023-14:30:02] [I] Precision: FP32
[05/28/2023-14:30:02] [I] LayerPrecisions: 
[05/28/2023-14:30:02] [I] Calibration: 
[05/28/2023-14:30:02] [I] Refit: Disabled
[05/28/2023-14:30:02] [I] Sparsity: Disabled
[05/28/2023-14:30:02] [I] Safe mode: Disabled
[05/28/2023-14:30:02] [I] DirectIO mode: Disabled
[05/28/2023-14:30:02] [I] Restricted mode: Disabled
[05/28/2023-14:30:02] [I] Build only: Disabled
[05/28/2023-14:30:02] [I] Save engine: sample.engine
[05/28/2023-14:30:02] [I] Load engine: 
[05/28/2023-14:30:02] [I] Profiling verbosity: 0
[05/28/2023-14:30:02] [I] Tactic sources: Using default tactic sources
[05/28/2023-14:30:02] [I] timingCacheMode: local
[05/28/2023-14:30:02] [I] timingCacheFile: 
[05/28/2023-14:30:02] [I] Heuristic: Disabled
[05/28/2023-14:30:02] [I] Preview Features: Use default preview flags.
[05/28/2023-14:30:02] [I] Input(s)s format: fp32:CHW
[05/28/2023-14:30:02] [I] Output(s)s format: fp32:CHW
[05/28/2023-14:30:02] [I] Input build shapes: model
[05/28/2023-14:30:02] [I] Input calibration shapes: model
[05/28/2023-14:30:02] [I] === System Options ===
[05/28/2023-14:30:02] [I] Device: 0
[05/28/2023-14:30:02] [I] DLACore: 
[05/28/2023-14:30:02] [I] Plugins:
[05/28/2023-14:30:02] [I] === Inference Options ===
[05/28/2023-14:30:02] [I] Batch: Explicit
[05/28/2023-14:30:02] [I] Input inference shapes: model
[05/28/2023-14:30:02] [I] Iterations: 50
[05/28/2023-14:30:02] [I] Duration: 3s (+ 200ms warm up)
[05/28/2023-14:30:02] [I] Sleep time: 0ms
[05/28/2023-14:30:02] [I] Idle time: 0ms
[05/28/2023-14:30:02] [I] Streams: 1
[05/28/2023-14:30:02] [I] ExposeDMA: Disabled
[05/28/2023-14:30:02] [I] Data transfers: Enabled
[05/28/2023-14:30:02] [I] Spin-wait: Disabled
[05/28/2023-14:30:02] [I] Multithreading: Disabled
[05/28/2023-14:30:02] [I] CUDA Graph: Disabled
[05/28/2023-14:30:02] [I] Separate profiling: Disabled
[05/28/2023-14:30:02] [I] Time Deserialize: Disabled
[05/28/2023-14:30:02] [I] Time Refit: Disabled
[05/28/2023-14:30:02] [I] NVTX verbosity: 0
[05/28/2023-14:30:02] [I] Persistent Cache Ratio: 0
[05/28/2023-14:30:02] [I] Inputs:
[05/28/2023-14:30:02] [I] === Reporting Options ===
[05/28/2023-14:30:02] [I] Verbose: Enabled
[05/28/2023-14:30:02] [I] Averages: 10 inferences
[05/28/2023-14:30:02] [I] Percentiles: 90,95,99
[05/28/2023-14:30:02] [I] Dump refittable layers:Disabled
[05/28/2023-14:30:02] [I] Dump output: Enabled
[05/28/2023-14:30:02] [I] Profile: Enabled
[05/28/2023-14:30:02] [I] Export timing to JSON file: 
[05/28/2023-14:30:02] [I] Export output to JSON file: log/sample/build/build_output.log
[05/28/2023-14:30:02] [I] Export profile to JSON file: log/sample/build/build_profile.log
[05/28/2023-14:30:02] [I] 
[05/28/2023-14:30:02] [I] === Device Information ===
[05/28/2023-14:30:02] [I] Selected Device: NVIDIA GeForce RTX 3080
[05/28/2023-14:30:02] [I] Compute Capability: 8.6
[05/28/2023-14:30:02] [I] SMs: 68
[05/28/2023-14:30:02] [I] Compute Clock Rate: 1.74 GHz
[05/28/2023-14:30:02] [I] Device Global Memory: 10009 MiB
[05/28/2023-14:30:02] [I] Shared Memory per SM: 100 KiB
[05/28/2023-14:30:02] [I] Memory Bus Width: 320 bits (ECC disabled)
[05/28/2023-14:30:02] [I] Memory Clock Rate: 9.501 GHz
[05/28/2023-14:30:02] [I] 
[05/28/2023-14:30:02] [I] TensorRT version: 8.5.1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::BatchedNMSDynamic_TRT version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::BatchedNMS_TRT version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::BatchTilePlugin_TRT version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::Clip_TRT version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::CoordConvAC version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::CropAndResizeDynamic version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::CropAndResize version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::DecodeBbox3DPlugin version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::DetectionLayer_TRT version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::EfficientNMS_Explicit_TF_TRT version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::EfficientNMS_Implicit_TF_TRT version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::EfficientNMS_ONNX_TRT version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::EfficientNMS_TRT version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::FlattenConcat_TRT version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::GenerateDetection_TRT version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::GridAnchor_TRT version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::GridAnchorRect_TRT version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 2
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::LReLU_TRT version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::MultilevelCropAndResize_TRT version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::MultilevelProposeROI_TRT version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::MultiscaleDeformableAttnPlugin_TRT version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::NMSDynamic_TRT version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::NMS_TRT version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::Normalize_TRT version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::PillarScatterPlugin version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::PriorBox_TRT version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::ProposalDynamic version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::ProposalLayer_TRT version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::Proposal version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::PyramidROIAlign_TRT version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::Region_TRT version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::Reorg_TRT version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::ResizeNearest_TRT version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::ROIAlign_TRT version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::RPROI_TRT version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::ScatterND version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::SpecialSlice_TRT version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::Split version 1
[05/28/2023-14:30:02] [V] [TRT] Registered plugin creator - ::VoxelGeneratorPlugin version 1
[05/28/2023-14:30:03] [I] [TRT] [MemUsageChange] Init CUDA: CPU +325, GPU +0, now: CPU 337, GPU 403 (MiB)
[05/28/2023-14:30:04] [V] [TRT] Trying to load shared library libnvinfer_builder_resource.so.8.5.1
[05/28/2023-14:30:04] [V] [TRT] Loaded shared library libnvinfer_builder_resource.so.8.5.1
[05/28/2023-14:30:12] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +441, GPU +118, now: CPU 833, GPU 521 (MiB)
[05/28/2023-14:30:12] [I] Start parsing network model
[05/28/2023-14:30:12] [I] [TRT] ----------------------------------------------------------------
[05/28/2023-14:30:12] [I] [TRT] Input filename:   sample.onnx
[05/28/2023-14:30:12] [I] [TRT] ONNX IR version:  0.0.8
[05/28/2023-14:30:12] [I] [TRT] Opset version:    15
[05/28/2023-14:30:12] [I] [TRT] Producer name:    pytorch
[05/28/2023-14:30:12] [I] [TRT] Producer version: 2.0.1
[05/28/2023-14:30:12] [I] [TRT] Domain:           
[05/28/2023-14:30:12] [I] [TRT] Model version:    0
[05/28/2023-14:30:12] [I] [TRT] Doc string:       
[05/28/2023-14:30:12] [I] [TRT] ----------------------------------------------------------------
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::BatchedNMSDynamic_TRT version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::BatchedNMS_TRT version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::BatchTilePlugin_TRT version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::Clip_TRT version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::CoordConvAC version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::CropAndResizeDynamic version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::CropAndResize version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::DecodeBbox3DPlugin version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::DetectionLayer_TRT version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::EfficientNMS_Explicit_TF_TRT version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::EfficientNMS_Implicit_TF_TRT version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::EfficientNMS_ONNX_TRT version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::EfficientNMS_TRT version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::FlattenConcat_TRT version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::GenerateDetection_TRT version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::GridAnchor_TRT version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::GridAnchorRect_TRT version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::InstanceNormalization_TRT version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::InstanceNormalization_TRT version 2
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::LReLU_TRT version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::MultilevelCropAndResize_TRT version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::MultilevelProposeROI_TRT version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::MultiscaleDeformableAttnPlugin_TRT version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::NMSDynamic_TRT version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::NMS_TRT version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::Normalize_TRT version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::PillarScatterPlugin version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::PriorBox_TRT version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::ProposalDynamic version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::ProposalLayer_TRT version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::Proposal version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::PyramidROIAlign_TRT version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::Region_TRT version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::Reorg_TRT version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::ResizeNearest_TRT version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::ROIAlign_TRT version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::RPROI_TRT version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::ScatterND version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::SpecialSlice_TRT version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::Split version 1
[05/28/2023-14:30:12] [V] [TRT] Plugin creator already registered - ::VoxelGeneratorPlugin version 1
[05/28/2023-14:30:12] [V] [TRT] Adding network input: input0 with dtype: float32, dimensions: (1, 10)
[05/28/2023-14:30:12] [V] [TRT] Registering tensor: input0 for ONNX tensor: input0
[05/28/2023-14:30:12] [V] [TRT] Importing initializer: onnx::MatMul_4
[05/28/2023-14:30:12] [V] [TRT] Parsing node: /linear/MatMul [MatMul]
[05/28/2023-14:30:12] [V] [TRT] Searching for input: input0
[05/28/2023-14:30:12] [V] [TRT] Searching for input: onnx::MatMul_4
[05/28/2023-14:30:12] [V] [TRT] /linear/MatMul [MatMul] inputs: [input0 -> (1, 10)[FLOAT]], [onnx::MatMul_4 -> (10, 5)[FLOAT]], 
[05/28/2023-14:30:12] [V] [TRT] Registering layer: onnx::MatMul_4 for ONNX node: onnx::MatMul_4
[05/28/2023-14:30:12] [V] [TRT] Registering layer: /linear/MatMul for ONNX node: /linear/MatMul
[05/28/2023-14:30:12] [V] [TRT] Registering tensor: output0_0 for ONNX tensor: output0
[05/28/2023-14:30:12] [V] [TRT] /linear/MatMul [MatMul] outputs: [output0 -> (1, 5)[FLOAT]], 
[05/28/2023-14:30:12] [V] [TRT] Marking output0_0 as output: output0
[05/28/2023-14:30:12] [I] Finish parsing network model
[05/28/2023-14:30:12] [V] [TRT] Original: 2 layers
[05/28/2023-14:30:12] [V] [TRT] After dead-layer removal: 2 layers
[05/28/2023-14:30:12] [V] [TRT] Applying generic optimizations to the graph for inference.
[05/28/2023-14:30:12] [V] [TRT] After Myelin optimization: 2 layers
[05/28/2023-14:30:12] [V] [TRT] Running: MatMulToConvTransform on /linear/MatMul
[05/28/2023-14:30:12] [V] [TRT] Convert layer type of /linear/MatMul from MATRIX_MULTIPLY to CONVOLUTION
[05/28/2023-14:30:12] [V] [TRT] Applying ScaleNodes fusions.
[05/28/2023-14:30:12] [V] [TRT] After scale fusion: 3 layers
[05/28/2023-14:30:12] [V] [TRT] After dupe layer removal: 3 layers
[05/28/2023-14:30:12] [V] [TRT] After final dead-layer removal: 3 layers
[05/28/2023-14:30:12] [V] [TRT] After tensor merging: 3 layers
[05/28/2023-14:30:12] [V] [TRT] After vertical fusions: 3 layers
[05/28/2023-14:30:12] [V] [TRT] After dupe layer removal: 3 layers
[05/28/2023-14:30:12] [V] [TRT] After final dead-layer removal: 3 layers
[05/28/2023-14:30:12] [V] [TRT] After tensor merging: 3 layers
[05/28/2023-14:30:12] [V] [TRT] After slice removal: 3 layers
[05/28/2023-14:30:12] [V] [TRT] After concat removal: 3 layers
[05/28/2023-14:30:12] [V] [TRT] Trying to split Reshape and strided tensor
[05/28/2023-14:30:12] [V] [TRT] Graph construction and optimization completed in 0.0798748 seconds.
[05/28/2023-14:30:12] [V] [TRT] Trying to load shared library libcublas.so.11
[05/28/2023-14:30:12] [V] [TRT] Loaded shared library libcublas.so.11
[05/28/2023-14:30:19] [V] [TRT] Using cublas as plugin tactic source
[05/28/2023-14:30:19] [V] [TRT] Trying to load shared library libcublasLt.so.11
[05/28/2023-14:30:19] [V] [TRT] Loaded shared library libcublasLt.so.11
[05/28/2023-14:30:19] [V] [TRT] Using cublasLt as core library tactic source
[05/28/2023-14:30:19] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +850, GPU +368, now: CPU 1683, GPU 889 (MiB)
[05/28/2023-14:30:19] [V] [TRT] Trying to load shared library libcudnn.so.8
[05/28/2023-14:30:19] [V] [TRT] Loaded shared library libcudnn.so.8
[05/28/2023-14:30:19] [V] [TRT] Using cuDNN as plugin tactic source
[05/28/2023-14:30:20] [V] [TRT] Using cuDNN as core library tactic source
[05/28/2023-14:30:20] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +125, GPU +58, now: CPU 1808, GPU 947 (MiB)
[05/28/2023-14:30:20] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.
[05/28/2023-14:30:20] [V] [TRT] Constructing optimization profile number 0 [1/1].
[05/28/2023-14:30:20] [V] [TRT] Reserving memory for host IO tensors. Host: 0 bytes
[05/28/2023-14:30:20] [V] [TRT] =============== Computing reformatting costs: 
[05/28/2023-14:30:20] [V] [TRT] *************** Autotuning Reformat: Float(10,1,1,1) -> Float(10,1,10,10) ***************
[05/28/2023-14:30:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> reshape_before_/linear/MatMul_out_tensor) (Reformat)
[05/28/2023-14:30:20] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00278541
[05/28/2023-14:30:20] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00629287
[05/28/2023-14:30:20] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00262118
[05/28/2023-14:30:20] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00262118
[05/28/2023-14:30:20] [V] [TRT] *************** Autotuning Reformat: Float(10,1,1,1) -> Float(3,1:4,3,3) ***************
[05/28/2023-14:30:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> reshape_before_/linear/MatMul_out_tensor) (Reformat)
[05/28/2023-14:30:20] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00291779
[05/28/2023-14:30:20] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00626127
[05/28/2023-14:30:20] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00268047
[05/28/2023-14:30:20] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00268047
[05/28/2023-14:30:20] [V] [TRT] =============== Computing reformatting costs: 
[05/28/2023-14:30:20] [V] [TRT] *************** Autotuning Reformat: Float(10,1,1,1) -> Float(10,1,10,10) ***************
[05/28/2023-14:30:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_/linear/MatMul_out_tensor -> <out>) (Reformat)
[05/28/2023-14:30:20] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00254444
[05/28/2023-14:30:20] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00624139
[05/28/2023-14:30:20] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00260089
[05/28/2023-14:30:20] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00254444
[05/28/2023-14:30:20] [V] [TRT] *************** Autotuning Reformat: Float(10,1,1,1) -> Float(3,1:4,3,3) ***************
[05/28/2023-14:30:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_/linear/MatMul_out_tensor -> <out>) (Reformat)
[05/28/2023-14:30:20] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00262724
[05/28/2023-14:30:20] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0062726
[05/28/2023-14:30:20] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00276273
[05/28/2023-14:30:20] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00262724
[05/28/2023-14:30:20] [V] [TRT] *************** Autotuning Reformat: Float(10,1,10,10) -> Float(10,1,1,1) ***************
[05/28/2023-14:30:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_/linear/MatMul_out_tensor -> <out>) (Reformat)
[05/28/2023-14:30:20] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00252126
[05/28/2023-14:30:20] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0062879
[05/28/2023-14:30:20] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00260588
[05/28/2023-14:30:20] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00252126
[05/28/2023-14:30:20] [V] [TRT] *************** Autotuning Reformat: Float(10,1,10,10) -> Float(3,1:4,3,3) ***************
[05/28/2023-14:30:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_/linear/MatMul_out_tensor -> <out>) (Reformat)
[05/28/2023-14:30:20] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.002624
[05/28/2023-14:30:20] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00589495
[05/28/2023-14:30:20] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00265135
[05/28/2023-14:30:20] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.002624
[05/28/2023-14:30:20] [V] [TRT] *************** Autotuning Reformat: Float(3,1:4,3,3) -> Float(10,1,1,1) ***************
[05/28/2023-14:30:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_/linear/MatMul_out_tensor -> <out>) (Reformat)
[05/28/2023-14:30:20] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00250365
[05/28/2023-14:30:20] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00624497
[05/28/2023-14:30:20] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00259865
[05/28/2023-14:30:20] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00250365
[05/28/2023-14:30:20] [V] [TRT] *************** Autotuning Reformat: Float(3,1:4,3,3) -> Float(10,1,10,10) ***************
[05/28/2023-14:30:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_/linear/MatMul_out_tensor -> <out>) (Reformat)
[05/28/2023-14:30:20] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00252479
[05/28/2023-14:30:20] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00587758
[05/28/2023-14:30:20] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00260164
[05/28/2023-14:30:20] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00252479
[05/28/2023-14:30:20] [V] [TRT] =============== Computing reformatting costs: 
[05/28/2023-14:30:20] [V] [TRT] *************** Autotuning Reformat: Float(5,1,5,5) -> Float(5,1,1,1) ***************
[05/28/2023-14:30:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/linear/MatMul_out_tensor -> <out>) (Reformat)
[05/28/2023-14:30:20] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00251116
[05/28/2023-14:30:20] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00635746
[05/28/2023-14:30:20] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00258147
[05/28/2023-14:30:20] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00251116
[05/28/2023-14:30:20] [V] [TRT] *************** Autotuning Reformat: Float(2,1:4,2,2) -> Float(5,1,1,1) ***************
[05/28/2023-14:30:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/linear/MatMul_out_tensor -> <out>) (Reformat)
[05/28/2023-14:30:20] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00254107
[05/28/2023-14:30:20] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00626425
[05/28/2023-14:30:20] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00259061
[05/28/2023-14:30:20] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00254107
[05/28/2023-14:30:20] [V] [TRT] =============== Computing costs for 
[05/28/2023-14:30:20] [V] [TRT] *************** Autotuning format combination: Float(10,1) -> Float(10,1,1,1) ***************
[05/28/2023-14:30:20] [V] [TRT] --------------- Timing Runner: reshape_before_/linear/MatMul (Shuffle)
[05/28/2023-14:30:20] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00270189
[05/28/2023-14:30:20] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.00939572
[05/28/2023-14:30:20] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00270189
[05/28/2023-14:30:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[05/28/2023-14:30:20] [V] [TRT] =============== Computing costs for 
[05/28/2023-14:30:20] [V] [TRT] *************** Autotuning format combination: Float(10,1,1,1) -> Float(5,1,1,1) ***************
[05/28/2023-14:30:20] [V] [TRT] --------------- Timing Runner: /linear/MatMul (CudaDepthwiseConvolution)
[05/28/2023-14:30:20] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/28/2023-14:30:20] [V] [TRT] --------------- Timing Runner: /linear/MatMul (FusedConvActConvolution)
[05/28/2023-14:30:20] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/28/2023-14:30:22] [V] [TRT] --------------- Timing Runner: /linear/MatMul (CudnnConvolution)
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00374001
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.00263298
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.00433538
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.0138211
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.0152974
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x0000000000000038 Time: 0.00322154
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x0000000000000039 Time: 0.00263273
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x000000000000003a Time: 0.004096
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x000000000000003c Time: 0.0114215
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x000000000000003d Time: 0.0130822
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x0000000000000070 Time: 0.00322458
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x0000000000000071 Time: 0.00324429
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x0000000000000072 Time: 0.004096
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x0000000000000074 Time: 0.0114215
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x0000000000000075 Time: 0.0131038
[05/28/2023-14:30:29] [V] [TRT] Fastest Tactic: 0x0000000000000039 Time: 0.00263273
[05/28/2023-14:30:29] [V] [TRT] --------------- Timing Runner: /linear/MatMul (CublasConvolution)
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00453543
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.00352892
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.00347733
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.00351153
[05/28/2023-14:30:29] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.00347733
[05/28/2023-14:30:29] [V] [TRT] Unrecognized MMA instruction source format or shape: sm50_xmma_cublas_gemvx_f32f32_f32_f32_tn_n_int32_unit_n_launch_param64x2x1_strided_copyx_unit_stride
[05/28/2023-14:30:29] [V] [TRT] Unrecognized MMA instruction source format or shape: sm50_xmma_cublas_gemvx_f32f32_f32_f32_tn_n_int32_unit_n_launch_param64x2x1_strided_unit_stride
[05/28/2023-14:30:29] [V] [TRT] Unrecognized MMA instruction source format or shape: sm50_xmma_cublas_gemvx_f32f32_f32_f32_tn_n_int32_unit_n_launch_param4x32x32_strided_copyx_unit_stride
[05/28/2023-14:30:29] [V] [TRT] Unrecognized MMA instruction source format or shape: sm50_xmma_cublas_gemvx_f32f32_f32_f32_tn_n_int32_unit_n_launch_param16x32x32_strided_copyx_unit_stride
[05/28/2023-14:30:29] [V] [TRT] Unrecognized MMA instruction source format or shape: sm50_xmma_cublas_gemvx_f32f32_f32_f32_tn_n_int32_unit_n_launch_param4x32x32_strided_unit_stride
[05/28/2023-14:30:29] [V] [TRT] Unrecognized MMA instruction source format or shape: sm50_xmma_cublas_gemvx_f32f32_f32_f32_tn_n_int32_unit_n_launch_param8x32x32_strided_unit_stride
[05/28/2023-14:30:29] [V] [TRT] Unrecognized MMA instruction source format or shape: sm70_xmma_gemm_as_conv1x1_f32f32_f32_f32_tn_n_simt_small_batch_bias_relu
[05/28/2023-14:30:29] [V] [TRT] Unrecognized MMA instruction source format or shape: sm50_xmma_cublas_gemvx_f32f32_f32_f32_tn_n_int32_unit_n_launch_param8x32x32_strided_copyx_unit_stride
[05/28/2023-14:30:29] [V] [TRT] Unrecognized MMA instruction source format or shape: sm50_xmma_cublas_gemvx_f32f32_f32_f32_tn_n_int32_unit_n_launch_param16x32x32_strided_unit_stride
[05/28/2023-14:30:29] [V] [TRT] /linear/MatMul: 24 available tactics, 24 unparsable, 0 pruned, 24 remaining after tactic pruning.
[05/28/2023-14:30:29] [V] [TRT] --------------- Timing Runner: /linear/MatMul (CaskGemmConvolution)
[05/28/2023-14:30:29] [V] [TRT] Set Tactic Name: sm50_xmma_cublas_gemvx_f32f32_f32_f32_tn_n_int32_unit_n_launch_param4x32x32_strided_copyx_unit_stride Tactic: 0x000000000002044a numSplitK: 1 numBuffers: 0 numKernels: 1
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x000000000002044a Time: 0.00343946
[05/28/2023-14:30:29] [V] [TRT] Set Tactic Name: ampere_sgemm_32x32_sliced1x4_relu_nn_v1 Tactic: 0x00000000000206cc numSplitK: 1 numBuffers: 0 numKernels: 1
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x00000000000206cc Time: 0.00472273
[05/28/2023-14:30:29] [V] [TRT] Set Tactic Name: ampere_sgemm_128x32_sliced1x4_relu_nn_v1 Tactic: 0x00000000000206aa numSplitK: 1 numBuffers: 0 numKernels: 1
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x00000000000206aa Time: 0.00634653
[05/28/2023-14:30:29] [V] [TRT] Set Tactic Name: sm50_xmma_cublas_gemvx_f32f32_f32_f32_tn_n_int32_unit_n_launch_param16x32x32_strided_unit_stride Tactic: 0x000000000002068d numSplitK: 1 numBuffers: 0 numKernels: 1
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x000000000002068d Time: 0.00320386
[05/28/2023-14:30:29] [V] [TRT] Set Tactic Name: ampere_sgemm_32x32_sliced1x4_tn_v1 Tactic: 0x0000000000020688 numSplitK: 1 numBuffers: 0 numKernels: 1
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x0000000000020688 Time: 0.00424605
[05/28/2023-14:30:29] [V] [TRT] Set Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4 Tactic: 0x000000000002065c numSplitK: 1 numBuffers: 0 numKernels: 1
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x000000000002065c Time: 0.00359074
[05/28/2023-14:30:29] [V] [TRT] Set Tactic Name: sm50_xmma_cublas_gemvx_f32f32_f32_f32_tn_n_int32_unit_n_launch_param8x32x32_strided_copyx_unit_stride Tactic: 0x0000000000020639 numSplitK: 1 numBuffers: 0 numKernels: 1
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x0000000000020639 Time: 0.00349201
[05/28/2023-14:30:29] [V] [TRT] Set Tactic Name: ampere_sgemm_64x32_sliced1x4_relu_nn_v1 Tactic: 0x0000000000020601 numSplitK: 1 numBuffers: 0 numKernels: 1
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x0000000000020601 Time: 0.00513943
[05/28/2023-14:30:29] [V] [TRT] Set Tactic Name: sm70_xmma_gemm_as_conv1x1_f32f32_f32_f32_tn_n_simt_small_batch_bias_relu Tactic: 0x00000000000205c0 numSplitK: 1 numBuffers: 0 numKernels: 1
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x00000000000205c0 Time: 0.00259649
[05/28/2023-14:30:29] [V] [TRT] Set Tactic Name: sm50_xmma_cublas_gemvx_f32f32_f32_f32_tn_n_int32_unit_n_launch_param8x32x32_strided_unit_stride Tactic: 0x00000000000204b2 numSplitK: 1 numBuffers: 0 numKernels: 1
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x00000000000204b2 Time: 0.00310857
[05/28/2023-14:30:29] [V] [TRT] Set Tactic Name: sm50_xmma_cublas_gemvx_f32f32_f32_f32_tn_n_int32_unit_n_launch_param4x32x32_strided_unit_stride Tactic: 0x0000000000020460 numSplitK: 1 numBuffers: 0 numKernels: 1
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x0000000000020460 Time: 0.00303838
[05/28/2023-14:30:29] [V] [TRT] Set Tactic Name: sm50_xmma_cublas_gemvx_f32f32_f32_f32_tn_n_int32_unit_n_launch_param16x32x32_strided_copyx_unit_stride Tactic: 0x000000000002045e numSplitK: 1 numBuffers: 0 numKernels: 1
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x000000000002045e Time: 0.00382268
[05/28/2023-14:30:29] [V] [TRT] Set Tactic Name: ampere_sgemm_64x32_sliced1x4_nn_v1 Tactic: 0x00000000000200b1 numSplitK: 1 numBuffers: 0 numKernels: 1
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x00000000000200b1 Time: 0.00472302
[05/28/2023-14:30:29] [V] [TRT] Set Tactic Name: sm50_xmma_cublas_gemvx_f32f32_f32_f32_tn_n_int32_unit_n_launch_param64x2x1_strided_unit_stride Tactic: 0x000000000002042a numSplitK: 1 numBuffers: 0 numKernels: 1
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x000000000002042a Time: 0.00273673
[05/28/2023-14:30:29] [V] [TRT] Set Tactic Name: sm50_xmma_cublas_gemvx_f32f32_f32_f32_tn_n_int32_unit_n_launch_param64x2x1_strided_copyx_unit_stride Tactic: 0x0000000000020419 numSplitK: 1 numBuffers: 0 numKernels: 1
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x0000000000020419 Time: 0.00311036
[05/28/2023-14:30:29] [V] [TRT] Set Tactic Name: ampere_sgemm_128x32_sliced1x4_tn_v1 Tactic: 0x0000000000020375 numSplitK: 1 numBuffers: 0 numKernels: 1
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x0000000000020375 Time: 0.00635965
[05/28/2023-14:30:29] [V] [TRT] Set Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize128x32x8_stage3_warpsize2x2x1_ffma_aligna4_alignc4 Tactic: 0x000000000002030f numSplitK: 1 numBuffers: 0 numKernels: 1
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x000000000002030f Time: 0.00432269
[05/28/2023-14:30:29] [V] [TRT] Set Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize64x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4 Tactic: 0x00000000000202e7 numSplitK: 1 numBuffers: 0 numKernels: 1
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x00000000000202e7 Time: 0.00401384
[05/28/2023-14:30:29] [V] [TRT] Set Tactic Name: ampere_sgemm_128x32_sliced1x4_nn_v1 Tactic: 0x000000000002021a numSplitK: 1 numBuffers: 0 numKernels: 1
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x000000000002021a Time: 0.00602514
[05/28/2023-14:30:29] [V] [TRT] Set Tactic Name: ampere_sgemm_32x32_sliced1x4_nn_v1 Tactic: 0x0000000000020201 numSplitK: 1 numBuffers: 0 numKernels: 1
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x0000000000020201 Time: 0.00428827
[05/28/2023-14:30:29] [V] [TRT] Set Tactic Name: ampere_sgemm_64x32_sliced1x4_tn_v1 Tactic: 0x000000000002019b numSplitK: 1 numBuffers: 0 numKernels: 1
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x000000000002019b Time: 0.00487573
[05/28/2023-14:30:29] [V] [TRT] Set Tactic Name: ampere_sgemm_64x32_sliced1x4_relu_tn_v1 Tactic: 0x0000000000020174 numSplitK: 1 numBuffers: 0 numKernels: 1
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x0000000000020174 Time: 0.00531572
[05/28/2023-14:30:29] [V] [TRT] Set Tactic Name: ampere_sgemm_32x32_sliced1x4_relu_tn_v1 Tactic: 0x000000000002014d numSplitK: 1 numBuffers: 0 numKernels: 1
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x000000000002014d Time: 0.00470872
[05/28/2023-14:30:29] [V] [TRT] Set Tactic Name: ampere_sgemm_128x32_sliced1x4_relu_tn_v1 Tactic: 0x0000000000020145 numSplitK: 1 numBuffers: 0 numKernels: 1
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x0000000000020145 Time: 0.00680468
[05/28/2023-14:30:29] [V] [TRT] Fastest Tactic: 0x00000000000205c0 Time: 0.00259649
[05/28/2023-14:30:29] [V] [TRT] --------------- Timing Runner: /linear/MatMul (CaskFlattenConvolution)
[05/28/2023-14:30:29] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[05/28/2023-14:30:29] [V] [TRT] --------------- Timing Runner: /linear/MatMul (CaskConvolution)
[05/28/2023-14:30:29] [V] [TRT] /linear/MatMul Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0xa8609adc4e0ceb90 Time: 0.00757341
[05/28/2023-14:30:29] [V] [TRT] /linear/MatMul Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0xf64396b97c889179 Time: 0.0083934
[05/28/2023-14:30:29] [V] [TRT] /linear/MatMul Set Tactic Name: ampere_scudnn_128x128_relu_interior_nn_v1 Tactic: 0xa8ef60e712f8ad24
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0xa8ef60e712f8ad24 Time: 0.00931114
[05/28/2023-14:30:29] [V] [TRT] /linear/MatMul Set Tactic Name: ampere_scudnn_128x64_relu_interior_nn_v1 Tactic: 0xc3cf6e1d1c6aff27
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0xc3cf6e1d1c6aff27 Time: 0.00813511
[05/28/2023-14:30:29] [V] [TRT] /linear/MatMul Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x503619c69ae500ff Time: 0.00947914
[05/28/2023-14:30:29] [V] [TRT] /linear/MatMul Set Tactic Name: ampere_scudnn_128x32_relu_interior_nn_v1 Tactic: 0x9808072e706def96
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x9808072e706def96 Time: 0.00737028
[05/28/2023-14:30:29] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xcb8a43f748d8a338
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0xcb8a43f748d8a338 Time: 0.00556202
[05/28/2023-14:30:29] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0xd828f024626fa982 Time: 0.00643995
[05/28/2023-14:30:29] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0xa31d27de74b895ff Time: 0.00549384
[05/28/2023-14:30:29] [V] [TRT] /linear/MatMul Set Tactic Name: sm70_xmma_fprop_conv1x1_f32f32_f32_f32_nchwkcrs_nchw_simt_small_batch_bias_relu Tactic: 0xaa0953b1a73b0b9b
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0xaa0953b1a73b0b9b Time: 0.002588
[05/28/2023-14:30:29] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xfff46c7893896eb1
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0xfff46c7893896eb1 Time: 0.0168564
[05/28/2023-14:30:29] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x40a12e3938221818
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x40a12e3938221818 Time: 0.00704523
[05/28/2023-14:30:29] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9cd5cdc35441c505
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x9cd5cdc35441c505 Time: 0.00795962
[05/28/2023-14:30:29] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fc87d7eb370bb7a
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x1fc87d7eb370bb7a Time: 0.00547048
[05/28/2023-14:30:29] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x12dbf7d94ee3696d Time: 0.00988251
[05/28/2023-14:30:29] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xe5603263b7f00303
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0xe5603263b7f00303 Time: 0.00970545
[05/28/2023-14:30:29] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x828d0ea88c66fce7
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x828d0ea88c66fce7 Time: 0.00569582
[05/28/2023-14:30:29] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9de226a0c44627c4
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x9de226a0c44627c4 Time: 0.0162403
[05/28/2023-14:30:29] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa9366041633a5135
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0xa9366041633a5135 Time: 0.00771513
[05/28/2023-14:30:29] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x8e3884f0eaec3ecd
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x8e3884f0eaec3ecd Time: 0.00822121
[05/28/2023-14:30:29] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0xbb8c3889c7eacd30 Time: 0.0196011
[05/28/2023-14:30:29] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xb0bf940d5e0f9f45
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0xb0bf940d5e0f9f45 Time: 0.00469899
[05/28/2023-14:30:29] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xc0b05b61d128e46e
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0xc0b05b61d128e46e Time: 0.00877499
[05/28/2023-14:30:29] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x9d9fdb5fd9945f64
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x9d9fdb5fd9945f64 Time: 0.00518008
[05/28/2023-14:30:29] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x5aa723e0481da855 Time: 0.00905257
[05/28/2023-14:30:29] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x2ee10e11d6651675
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x2ee10e11d6651675 Time: 0.0174243
[05/28/2023-14:30:29] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x865894c4635db7fd
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x865894c4635db7fd Time: 0.00554708
[05/28/2023-14:30:29] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90f8f2915f87ed77
[05/28/2023-14:30:29] [V] [TRT] Tactic: 0x90f8f2915f87ed77 Time: 0.00453171
[05/28/2023-14:30:29] [V] [TRT] /linear/MatMul Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x3f243c490d502deb Time: 0.0082273
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xf067e6205da31c2e Time: 0.00954484
[05/28/2023-14:30:30] [V] [TRT] Fastest Tactic: 0xaa0953b1a73b0b9b Time: 0.002588
[05/28/2023-14:30:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xaa0953b1a73b0b9b
[05/28/2023-14:30:30] [V] [TRT] *************** Autotuning format combination: Float(10,1,10,10) -> Float(5,1,5,5) ***************
[05/28/2023-14:30:30] [V] [TRT] --------------- Timing Runner: /linear/MatMul (CublasConvolution)
[05/28/2023-14:30:30] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/28/2023-14:30:30] [V] [TRT] --------------- Timing Runner: /linear/MatMul (CaskFlattenConvolution)
[05/28/2023-14:30:30] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[05/28/2023-14:30:30] [V] [TRT] --------------- Timing Runner: /linear/MatMul (CaskConvolution)
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x35f26f9c09557d86
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x35f26f9c09557d86 Time: 0.00744846
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xc7b3afceb5fb03c0
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xc7b3afceb5fb03c0 Time: 0.00702215
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc4 Tactic: 0xf78ec258f27b3e23
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xf78ec258f27b3e23 Time: 0.00375561
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x7121ec1db3f80c67
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x7121ec1db3f80c67 Time: 0.00436848
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd9eb6ca56ddc3a22
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xd9eb6ca56ddc3a22 Time: 0.00528098
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xbc0bba0ff1a92939
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xbc0bba0ff1a92939 Time: 0.0147749
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x19b688348f983aa0 Time: 0.00544999
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x0a143be7a52f301a
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x0a143be7a52f301a Time: 0.00431502
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x62835fce994f06dd Time: 0.00564149
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x1022069e6f8d9aeb
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x1022069e6f8d9aeb Time: 0.0073136
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90898977fc8ce537
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x90898977fc8ce537 Time: 0.00530946
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x92ed3100c35fc43e
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x92ed3100c35fc43e Time: 0.00483581
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc4 Tactic: 0x93030576a9fb03f9
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x93030576a9fb03f9 Time: 0.00531471
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x4fd3c46622e98342
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x4fd3c46622e98342 Time: 0.00489417
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd55ee6fd0b56f808
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xd55ee6fd0b56f808 Time: 0.00695946
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x1da91d865428f237 Time: 0.00847274
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa6448a1e79f1ca6f
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xa6448a1e79f1ca6f Time: 0.00560176
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc4 Tactic: 0xcf8ea142095f02d2
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xcf8ea142095f02d2 Time: 0.00450529
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fb90698107bb33a
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x1fb90698107bb33a Time: 0.00418704
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc4 Tactic: 0xab0496509b88ebe0
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xab0496509b88ebe0 Time: 0.00448929
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x55d80c17b1cd982d
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x55d80c17b1cd982d Time: 0.00563587
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc4 Tactic: 0xf231cca3335919a4
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xf231cca3335919a4 Time: 0.00398006
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x8014228ec08b4d49 Time: 0.0166923
[05/28/2023-14:30:30] [V] [TRT] Fastest Tactic: 0xf78ec258f27b3e23 Time: 0.00375561
[05/28/2023-14:30:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xf78ec258f27b3e23
[05/28/2023-14:30:30] [V] [TRT] *************** Autotuning format combination: Float(3,1:4,3,3) -> Float(2,1:4,2,2) ***************
[05/28/2023-14:30:30] [V] [TRT] --------------- Timing Runner: /linear/MatMul (CudaDepthwiseConvolution)
[05/28/2023-14:30:30] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/28/2023-14:30:30] [V] [TRT] --------------- Timing Runner: /linear/MatMul (CublasConvolution)
[05/28/2023-14:30:30] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul: 2 available tactics, 2 unparsable, 0 pruned, 2 remaining after tactic pruning.
[05/28/2023-14:30:30] [V] [TRT] --------------- Timing Runner: /linear/MatMul (CaskGemmConvolution)
[05/28/2023-14:30:30] [V] [TRT] Set Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x8 Tactic: 0x0000000000020386 numSplitK: 1 numBuffers: 0 numKernels: 1
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x0000000000020386 Time: 0.0037195
[05/28/2023-14:30:30] [V] [TRT] Set Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x32x64_stage4_warpsize2x2x1_tensor16x8x8 Tactic: 0x00000000000204ec numSplitK: 1 numBuffers: 0 numKernels: 1
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x00000000000204ec Time: 0.00416483
[05/28/2023-14:30:30] [V] [TRT] Fastest Tactic: 0x0000000000020386 Time: 0.0037195
[05/28/2023-14:30:30] [V] [TRT] --------------- Timing Runner: /linear/MatMul (CaskFlattenConvolution)
[05/28/2023-14:30:30] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[05/28/2023-14:30:30] [V] [TRT] --------------- Timing Runner: /linear/MatMul (CaskConvolution)
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 0x17173deba0b64484
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x17173deba0b64484 Time: 0.00779717
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x3e2b881168d9689d
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x3e2b881168d9689d Time: 0.00685366
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0xf90060ce8193b811
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xf90060ce8193b811 Time: 0.00771489
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: 0xd9031472c05adf51
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xd9031472c05adf51 Time: 0.00790713
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xe47307053a42b3e4
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xe47307053a42b3e4 Time: 0.00764463
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x412c44dfeaf9161d
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x412c44dfeaf9161d Time: 0.00684474
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x27b316f52c109002
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x27b316f52c109002 Time: 0.00685888
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xae0c89d047932ba3
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xae0c89d047932ba3 Time: 0.00668239
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x7bc32c782b800c48 Time: 0.0077618
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x35f26f9c09557d86
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x35f26f9c09557d86 Time: 0.00743749
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xc7b3afceb5fb03c0
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xc7b3afceb5fb03c0 Time: 0.0070252
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc4 Tactic: 0xf78ec258f27b3e23
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xf78ec258f27b3e23 Time: 0.00372431
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x7121ec1db3f80c67
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x7121ec1db3f80c67 Time: 0.00435338
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 0x5030121339a48bf3
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x5030121339a48bf3 Time: 0.00790183
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x9dece0dc37e90462
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x9dece0dc37e90462 Time: 0.00645923
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd9eb6ca56ddc3a22
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xd9eb6ca56ddc3a22 Time: 0.00525829
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc8 Tactic: 0x1acd4f006848c62b
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x1acd4f006848c62b Time: 0.00628214
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xbc0bba0ff1a92939
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xbc0bba0ff1a92939 Time: 0.0148155
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x19b688348f983aa0 Time: 0.00545456
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x0a143be7a52f301a
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x0a143be7a52f301a Time: 0.00431623
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x62835fce994f06dd Time: 0.00565187
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xc7feb33970feefa7
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xc7feb33970feefa7 Time: 0.00671938
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x1022069e6f8d9aeb
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x1022069e6f8d9aeb Time: 0.00727611
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc4 Tactic: 0xcc46f0f5cee60677
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xcc46f0f5cee60677 Time: 0.00400876
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90898977fc8ce537
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x90898977fc8ce537 Time: 0.00535009
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x92ed3100c35fc43e
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x92ed3100c35fc43e Time: 0.00483154
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc4 Tactic: 0x93030576a9fb03f9
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x93030576a9fb03f9 Time: 0.00528359
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8 Tactic: 0xdb77237fa21087f5
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xdb77237fa21087f5 Time: 0.00371997
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x130df49cb195156b Time: 0.00681796
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4 Tactic: 0xb3e5ce9d1b1da232
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xb3e5ce9d1b1da232 Time: 0.00426864
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x4fd3c46622e98342
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x4fd3c46622e98342 Time: 0.00489158
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x65e41d81f093b482
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x65e41d81f093b482 Time: 0.00642703
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc8 Tactic: 0x3a8712b17741b582
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x3a8712b17741b582 Time: 0.00467937
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd55ee6fd0b56f808
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xd55ee6fd0b56f808 Time: 0.00695336
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x1da91d865428f237 Time: 0.00844773
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa6448a1e79f1ca6f
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xa6448a1e79f1ca6f Time: 0.00560756
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 0xb33296dda7141c64
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xb33296dda7141c64 Time: 0.00467362
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc8 Tactic: 0x7bff86d5f2eadc76
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x7bff86d5f2eadc76 Time: 0.00352413
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc4 Tactic: 0xcf8ea142095f02d2
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xcf8ea142095f02d2 Time: 0.00385973
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fb90698107bb33a
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x1fb90698107bb33a Time: 0.00373451
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc8 Tactic: 0x22cadc265a3b2e32
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x22cadc265a3b2e32 Time: 0.00512702
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc4 Tactic: 0xab0496509b88ebe0
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xab0496509b88ebe0 Time: 0.00396405
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x55d80c17b1cd982d
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x55d80c17b1cd982d Time: 0.00495338
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 0xae48d3ccfe1edfcd
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xae48d3ccfe1edfcd Time: 0.00319776
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xb443c221fcb1565b Time: 0.00588727
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc4 Tactic: 0xfed494d61b2087ba
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xfed494d61b2087ba Time: 0.00327304
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc4 Tactic: 0x1a373db9a2bc4028
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x1a373db9a2bc4028 Time: 0.00320894
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8 Tactic: 0xe9e5475c77d60638
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xe9e5475c77d60638 Time: 0.00398336
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc8 Tactic: 0x72a5d05b1bb165ef
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x72a5d05b1bb165ef Time: 0.00325777
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc8 Tactic: 0x96467934a22da27d
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x96467934a22da27d Time: 0.00321453
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 0x10383a0781d24dde
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x10383a0781d24dde Time: 0.00354397
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc8 Tactic: 0x4037b478ce77e422
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x4037b478ce77e422 Time: 0.00355178
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8 Tactic: 0x3f948a101b8c4067
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x3f948a101b8c4067 Time: 0.00333884
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 0x9cb304e2edbc1221
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x9cb304e2edbc1221 Time: 0.00325216
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc4 Tactic: 0xf231cca3335919a4
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xf231cca3335919a4 Time: 0.00350539
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8 Tactic: 0x9355e195cee05798
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x9355e195cee05798 Time: 0.00461257
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc8 Tactic: 0x7e40882e33c8fbf1
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x7e40882e33c8fbf1 Time: 0.00360629
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x3e191488237fab8f
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x3e191488237fab8f Time: 0.00610781
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc4 Tactic: 0xb6f6563c77d057d7
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0xb6f6563c77d057d7 Time: 0.00416444
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4 Tactic: 0x570667f2a28165a0
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x570667f2a28165a0 Time: 0.00339476
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc8 Tactic: 0x43ffe5cf09cee087
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x43ffe5cf09cee087 Time: 0.00383266
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc8 Tactic: 0x4640eb34c8ecc700
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x4640eb34c8ecc700 Time: 0.0033971
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x8014228ec08b4d49 Time: 0.0146542
[05/28/2023-14:30:30] [V] [TRT] Fastest Tactic: 0xae48d3ccfe1edfcd Time: 0.00319776
[05/28/2023-14:30:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xae48d3ccfe1edfcd
[05/28/2023-14:30:30] [V] [TRT] =============== Computing costs for 
[05/28/2023-14:30:30] [V] [TRT] *************** Autotuning format combination: Float(5,1,1,1) -> Float(5,1) ***************
[05/28/2023-14:30:30] [V] [TRT] --------------- Timing Runner: reshape_after_/linear/MatMul (Shuffle)
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00269714
[05/28/2023-14:30:30] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.00824889
[05/28/2023-14:30:30] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00269714
[05/28/2023-14:30:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[05/28/2023-14:30:30] [V] [TRT] Formats and tactics selection completed in 9.46598 seconds.
[05/28/2023-14:30:30] [V] [TRT] After reformat layers: 3 layers
[05/28/2023-14:30:30] [V] [TRT] Total number of blocks in pre-optimized block assignment: 3
[05/28/2023-14:30:30] [I] [TRT] Total Activation Memory: 2147484672
[05/28/2023-14:30:30] [I] [TRT] Detected 1 inputs and 1 output network tensors.
[05/28/2023-14:30:30] [V] [TRT] /linear/MatMul Set Tactic Name: sm70_xmma_fprop_conv1x1_f32f32_f32_f32_nchwkcrs_nchw_simt_small_batch_bias_relu Tactic: 0xaa0953b1a73b0b9b
[05/28/2023-14:30:30] [V] [TRT] Layer: /linear/MatMul Host Persistent: 2880 Device Persistent: 0 Scratch Memory: 0
[05/28/2023-14:30:30] [V] [TRT] Skipped printing memory information for 2 layers with 0 memory size i.e. Host Persistent + Device Persistent + Scratch Memory == 0.
[05/28/2023-14:30:30] [I] [TRT] Total Host Persistent Memory: 2880
[05/28/2023-14:30:30] [I] [TRT] Total Device Persistent Memory: 0
[05/28/2023-14:30:30] [I] [TRT] Total Scratch Memory: 0
[05/28/2023-14:30:30] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 5 MiB
[05/28/2023-14:30:30] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 2 steps to complete.
[05/28/2023-14:30:30] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 0.01036ms to assign 2 blocks to 2 nodes requiring 1024 bytes.
[05/28/2023-14:30:30] [V] [TRT] Total number of blocks in optimized block assignment: 2
[05/28/2023-14:30:30] [I] [TRT] Total Activation Memory: 1024
[05/28/2023-14:30:30] [V] [TRT] Finalize: /linear/MatMul Set kernel index: 0
[05/28/2023-14:30:30] [V] [TRT] Total number of generated kernels selected for the engine: 1
[05/28/2023-14:30:30] [V] [TRT] Kernel: 0 CASK_STATIC
[05/28/2023-14:30:30] [V] [TRT] Disabling unused tactic source: CUDNN
[05/28/2023-14:30:30] [V] [TRT] Disabling unused tactic source: CUBLAS, CUBLAS_LT
[05/28/2023-14:30:30] [V] [TRT] Disabling unused tactic source: JIT_CONVOLUTIONS
[05/28/2023-14:30:30] [V] [TRT] Engine generation completed in 17.3818 seconds.
[05/28/2023-14:30:30] [V] [TRT] Deleting timing cache: 15 entries, served 0 hits since creation.
[05/28/2023-14:30:30] [V] [TRT] Engine Layer Information:
Layer(NoOp): reshape_before_/linear/MatMul, Tactic: 0x0000000000000000, input0 (Float[1,10]) -> reshape_before_/linear/MatMul_out_tensor (Float[1,10,1,1])
Layer(CaskConvolution): /linear/MatMul, Tactic: 0xaa0953b1a73b0b9b, reshape_before_/linear/MatMul_out_tensor (Float[1,10,1,1]) -> /linear/MatMul_out_tensor (Float[1,5,1,1])
Layer(NoOp): reshape_after_/linear/MatMul, Tactic: 0x0000000000000000, /linear/MatMul_out_tensor (Float[1,5,1,1]) -> output0 (Float[1,5])
[05/28/2023-14:30:30] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +4, now: CPU 0, GPU 4 (MiB)
[05/28/2023-14:30:30] [I] Engine built in 28.0953 sec.
[05/28/2023-14:30:30] [I] [TRT] Loaded engine size: 0 MiB
[05/28/2023-14:30:30] [V] [TRT] Deserialization required 1741 microseconds.
[05/28/2023-14:30:30] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)
[05/28/2023-14:30:30] [I] Engine deserialized in 0.00192521 sec.
[05/28/2023-14:30:30] [V] [TRT] Total per-runner device persistent memory is 0
[05/28/2023-14:30:30] [V] [TRT] Total per-runner host persistent memory is 2880
[05/28/2023-14:30:30] [V] [TRT] Allocated activation device memory of size 1024
[05/28/2023-14:30:30] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)
[05/28/2023-14:30:30] [I] Setting persistentCacheLimit to 0 bytes.
[05/28/2023-14:30:30] [V] Using enqueueV3.
[05/28/2023-14:30:30] [I] Using random values for input input0
[05/28/2023-14:30:30] [I] Created input binding for input0 with dimensions 1x10
[05/28/2023-14:30:30] [I] Using random values for output output0
[05/28/2023-14:30:30] [I] Created output binding for output0 with dimensions 1x5
[05/28/2023-14:30:30] [I] Layer Information:
[05/28/2023-14:30:30] [I] [TRT] The profiling verbosity was set to ProfilingVerbosity::kLAYER_NAMES_ONLY when the engine was built, so only the layer names will be returned. Rebuild the engine with ProfilingVerbosity::kDETAILED to get more verbose layer information.
[05/28/2023-14:30:30] [I] Layers:
reshape_before_/linear/MatMul
/linear/MatMul
reshape_after_/linear/MatMul

Bindings:
input0
output0
[05/28/2023-14:30:30] [I] [TRT] The profiling verbosity was set to ProfilingVerbosity::kLAYER_NAMES_ONLY when the engine was built, so only the layer names will be returned. Rebuild the engine with ProfilingVerbosity::kDETAILED to get more verbose layer information.
[05/28/2023-14:30:30] [I] Starting inference
[05/28/2023-14:30:33] [I] The e2e network timing is not reported since it is inaccurate due to the extra synchronizations when the profiler is enabled.
[05/28/2023-14:30:33] [I] To show e2e network timing report, add --separateProfileRun to profile layer timing in a separate run or remove --dumpProfile to disable the profiler.
[05/28/2023-14:30:33] [I] Output Tensors:
[05/28/2023-14:30:33] [I] output0: (1x5)
[05/28/2023-14:30:33] [I] -1.45693 -2.53553 -1.34375 -0.175525 0.541239
[05/28/2023-14:30:33] [I] 
[05/28/2023-14:30:33] [I] === Profile (132395 iterations ) ===
[05/28/2023-14:30:33] [I]                          Layer   Time (ms)   Avg. Time (ms)   Median Time (ms)   Time %
[05/28/2023-14:30:33] [I]                 /linear/MatMul      440.63           0.0033             0.0031    100.0
[05/28/2023-14:30:33] [I]                          Total      440.63           0.0033             0.0031    100.0
[05/28/2023-14:30:33] [I] 
&&&& PASSED TensorRT.trtexec [TensorRT v8501] # trtexec --onnx=sample.onnx --memPoolSize=workspace:2048 --saveEngine=sample.engine --verbose --profilingVerbosity=layer_names_only --dumpOutput --dumpProfile --dumpLayerInfo --exportOutput=log/sample/build/build_output.log --exportProfile=log/sample/build/build_profile.log --exportLayerInfo=log/sample/build/build_layer_info.log --warmUp=200 --iterations=50
